import os
import sqlite3
import pandas as pd
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload
from google.oauth2.service_account import Credentials
import io
import json

# å°å…¥è‡ªå®šç¾©æ¨¡çµ„
from market_rules import MarketRuleRouter
from core_engine import AlphaCoreEngine

class AlphaDataPipeline:
    def __init__(self, market_abbr):
        self.market_abbr = market_abbr.upper()
        # è‡ªå‹•ç”Ÿæˆçš„æª”åï¼šä¾‹å¦‚ tw_stock_warehouse.db
        self.db_name = f"{self.market_abbr.lower()}_stock_warehouse.db"
        self.creds = self._load_credentials()
        self.service = build('drive', 'v3', credentials=self.creds)

    def _load_credentials(self):
        creds_json = os.environ.get("GDRIVE_SERVICE_ACCOUNT")
        if not creds_json:
            raise ValueError("âŒ æ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸: GDRIVE_SERVICE_ACCOUNT")
        return Credentials.from_service_account_info(json.loads(creds_json))

    def find_file_id_by_name(self, filename):
        """
        ğŸš€ æ¢å¾©è‡ªå‹•åŒ–ï¼šé€éæª”ååœ¨ Google Drive æœå°‹æª”æ¡ˆ ID
        """
        query = f"name = '{filename}' and trashed = false"
        results = self.service.files().list(q=query, fields="files(id, name)").execute()
        files = results.get('files', [])
        if not files:
            raise ValueError(f"âŒ åœ¨é›²ç«¯æ‰¾ä¸åˆ°æª”æ¡ˆ: {filename}")
        return files[0]['id']

    def download_db(self):
        # è‡ªå‹•æ‰¾ ID
        file_id = self.find_file_id_by_name(self.db_name)
        
        print(f"ğŸ“¥ åµæ¸¬åˆ°é›²ç«¯æª”æ¡ˆ ID: {file_id}ï¼Œé–‹å§‹ä¸‹è¼‰...")
        request = self.service.files().get_media(fileId=file_id)
        fh = io.FileIO(self.db_name, 'wb')
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while not done:
            status, done = downloader.next_chunk()
        print(f"âœ… {self.db_name} ä¸‹è¼‰æˆåŠŸ")

    def upload_db(self):
        # è‡ªå‹•æ‰¾ ID
        file_id = self.find_file_id_by_name(self.db_name)
        
        # ğŸš€ ä¿ç•™è§£æ±ºç¾åœ‹å¤§æª”æ¡ˆçš„ Resumable æŠ€è¡“
        media = MediaFileUpload(self.db_name, mimetype='application/octet-stream', resumable=True)
        request = self.service.files().update(fileId=file_id, media_body=media)
        
        print(f"ğŸ“¤ æ­£åœ¨åŒæ­¥å›é›²ç«¯ (å¯çºŒå‚³æ¨¡å¼)...")
        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                print(f"   > é€²åº¦: {int(status.progress() * 100)}%")
        print(f"âœ… {self.market_abbr} é›²ç«¯åŒæ­¥æˆåŠŸ")

    def run_process(self):
        self.download_db()
        conn = sqlite3.connect(self.db_name)
        try:
            rules = MarketRuleRouter.get_rules(self.market_abbr)
            engine = AlphaCoreEngine(conn, rules, self.market_abbr)
            summary_msg = engine.execute()
            conn.close()
            
            self.upload_db()
            
            # ç”Ÿæˆæ‘˜è¦ä¾›å ±å‘Šä½¿ç”¨
            summary_file = f"summary_{self.market_abbr.lower()}_stock_warehouse.txt"
            with open(summary_file, "w", encoding="utf-8") as f:
                f.write(str(summary_msg))
            return summary_msg
        except Exception as e:
            if conn: conn.close()
            raise e

if __name__ == "__main__":
    target_market = os.environ.get("MARKET_TYPE")
    if not target_market:
        # å¦‚æœæ²’æœ‰è¨­å®šè®Šæ•¸ï¼Œå˜—è©¦å¾ matrix æŒ‡ä»¤æŠ“å–ï¼ˆé€™å°æ‡‰ä½ çš„ YAML æ”¹å‹•ï¼‰
        print("âŒ éŒ¯èª¤ï¼šæœªè¨­å®š MARKET_TYPE")
        exit(1)
    
    pipeline = AlphaDataPipeline(target_market)
    pipeline.run_process()
