# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np

class AlphaCoreEngine:
    def __init__(self, conn, rules, market_abbr):
        self.conn = conn
        self.rules = rules
        self.market_abbr = market_abbr

    def _auto_map_columns(self, df):
        """è‡ªå‹•è­˜åˆ¥æ¬„ä½åç¨±ï¼Œå°‡å…¶çµ±ä¸€åç¨±ç‚ºæ¨™æº–ä¸­æ–‡"""
        cands = {
            'æ—¥æœŸ': ['æ—¥æœŸ', 'Date', 'date', 'time', 'Time', 'datetime'],
            'StockID': ['StockID', 'symbol', 'Symbol', 'code', 'Code', 'Ticker'],
            'é–‹ç›¤': ['é–‹ç›¤', 'é–‹ç›¤åƒ¹', 'Open', 'open'],
            'æœ€é«˜': ['æœ€é«˜', 'æœ€é«˜åƒ¹', 'High', 'high'],
            'æœ€ä½': ['æœ€ä½', 'æœ€ä½åƒ¹', 'Low', 'low'],
            'æ”¶ç›¤': ['æ”¶ç›¤', 'æ”¶ç›¤åƒ¹', 'Close', 'close', 'Adj Close'],
            'æˆäº¤é‡': ['æˆäº¤é‡', 'Volume', 'volume', 'vol', 'Vol']
        }
        
        rename_dict = {}
        for target, aliases in cands.items():
            for alias in aliases:
                if alias in df.columns:
                    rename_dict[alias] = target
                    break
        return df.rename(columns=rename_dict)

    def execute(self):
        # 1. å‹•æ…‹åµæ¸¬è³‡æ–™è¡¨
        cursor = self.conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
        tables = [t[0] for t in cursor.fetchall()]
        
        target_table = 'daily_prices' if 'daily_prices' in tables else \
                       [t for t in tables if t != 'cleaned_daily_base'][0]
        
        print(f"ğŸ” {self.market_abbr}: ä½¿ç”¨è³‡æ–™è¡¨ '{target_table}'")
        df = pd.read_sql(f"SELECT * FROM {target_table}", self.conn)

        # 2. è‡ªå‹•ä¿®æ­£æ¬„ä½åç¨± (è§£æ±º KeyError: 'æ—¥æœŸ' çš„é—œéµ)
        df = self._auto_map_columns(df)
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½æ˜¯å¦å‚™é½Š
        required = ['æ—¥æœŸ', 'StockID', 'æ”¶ç›¤']
        missing = [r for r in required if r not in df.columns]
        if missing:
            raise ValueError(f"âŒ {self.market_abbr}: æ¬„ä½ç¼ºå¤± {missing}ã€‚ç¾æœ‰æ¬„ä½: {list(df.columns)}")

        # 3. åŸºç¤é è™•ç†
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
        df = df.dropna(subset=['æ—¥æœŸ'])
        df = df.sort_values(['StockID', 'æ—¥æœŸ']).reset_index(drop=True)

        # 4. æ¸…æ´—èˆ‡è¡ç”ŸæŒ‡æ¨™
        df = self._clean_data(df)
        df = self._calculate_base_metrics(df)

        # 5. åœ‹åˆ¥æ¼²è·Œåœåˆ¤å®š (is_limit_up, Limit_Price, is_anomaly)
        df = self.rules.apply(df)

        # 6. æ¼²åœè¡Œç‚ºåˆ†é¡èˆ‡éš”æ—¥æ²–æ­»æ³•
        df = self._calculate_pattern_analysis(df)

        # 7. æœªä¾†å ±é…¬åˆ†ä½ˆ (T+1 ~ T+20)
        df = self._calculate_forward_returns(df)

        # 8. å­˜å…¥è³‡æ–™åº«
        df.to_sql("cleaned_daily_base", self.conn, if_exists='replace', index=False)
        self.conn.execute("CREATE INDEX IF NOT EXISTS idx_sid_date ON cleaned_daily_base (StockID, æ—¥æœŸ)")
        
        return f"{self.market_abbr}: æˆåŠŸç²¾ç…‰ {len(df)} ç­†ï¼Œç™¼ç¾ {df['is_limit_up'].sum()} æ¬¡æ¼²åœ"

    def _clean_data(self, df):
        # æ’é™¤ Ghost Row
        if all(c in df.columns for c in ['æˆäº¤é‡', 'é–‹ç›¤', 'æ”¶ç›¤', 'æœ€é«˜', 'æœ€ä½']):
            mask_ghost = (df['æˆäº¤é‡'] == 0) & (df['é–‹ç›¤'] == df['æ”¶ç›¤']) & (df['æœ€é«˜'] == df['æœ€ä½'])
            return df[~mask_ghost].copy()
        return df

    def _calculate_base_metrics(self, df):
        df['PrevClose'] = df.groupby('StockID')['æ”¶ç›¤'].shift(1)
        df['Ret_Day'] = df['æ”¶ç›¤'] / df['PrevClose'] - 1
        if 'æˆäº¤é‡' in df.columns:
            df['Vol_MA5'] = df.groupby('StockID')['æˆäº¤é‡'].transform(lambda x: x.rolling(5).mean())
            df['Vol_Ratio'] = df['æˆäº¤é‡'] / df.groupby('StockID')['Vol_MA5'].shift(1)
        else:
            df['Vol_Ratio'] = 1.0
        return df

    def _calculate_pattern_analysis(self, df):
        df['Prev_LU'] = df.groupby('StockID')['is_limit_up'].shift(1).fillna(False)
        df['Overnight_Alpha'] = (df['é–‹ç›¤'] / df['PrevClose'] - 1).where(df['Prev_LU'])
        
        # å‘¼å« Rules é‚è¼¯
        df['LU_Type4'] = df.apply(lambda r: self.rules.classify_lu_type4(r, r.get('Limit_Price', 0)) if r['is_limit_up'] else 0, axis=1)
        df['Fail_Type'] = df.apply(lambda r: self.rules.classify_fail_type(r) if r['Prev_LU'] else 0, axis=1)
        
        # é€£æ¿è¨ˆæ•¸
        df['Seq_LU_Count'] = df.groupby((df['is_limit_up'] != df.groupby('StockID')['is_limit_up'].shift()).cumsum())['is_limit_up'].cumsum()
        df.loc[~df['is_limit_up'], 'Seq_LU_Count'] = 0
        return df

    def _calculate_forward_returns(self, df):
        # æ»¾å‹•æœªä¾†å ±é…¬
        def get_fwd(col, shift_s, win):
            return df.groupby('StockID')[col].shift(-shift_s).rolling(win, min_periods=1)

        if 'æœ€é«˜' in df.columns and 'æœ€ä½' in df.columns:
            df['Next_1D_Max'] = (df.groupby('StockID')['æœ€é«˜'].shift(-1) / df['æ”¶ç›¤']) - 1
            df['Fwd_5D_Max'] = (get_fwd('æœ€é«˜', 1, 5).max() / df['æ”¶ç›¤']) - 1
            df['Fwd_5D_Min'] = (get_fwd('æœ€ä½', 1, 5).min() / df['æ”¶ç›¤']) - 1
            df['Fwd_11_20D_Max'] = (get_fwd('æœ€é«˜', 11, 10).max() / df['æ”¶ç›¤']) - 1
        return df
